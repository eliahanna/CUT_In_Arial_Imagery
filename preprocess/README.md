The preprocessing creates the folders in a structure which can be consumed by domain transfer algorithms and calssification algorithms.

The program takes 3 file inputs . dataselect_config.json ( determines whether the program runs for all images , only particualar labels , only for a category) , category_id.json ( label mapping to ids. The ids would be used as classes for the classsification algorithm and folder generation , category_label.json ( mapping of labels to category).

Following are the folders that get generated : a) output : This has all subfolders which are generated (model , cut). Also it has 3 files labelall.csv ( All labels for all images) , labelsummary.csv ( label , category counts) , labelselected.csv ( selected labels for the current run) a) Model : This has all the data relevant for classification. Model has 3 folders train , test , validate. Each folder has images stored inside by the label. b) CUT : This has the data relevant for the domain transfer model. It has 2 subfolders dataset , test. dataset folder has 2 subfolders trainA and trainB . It is used as an input for domain transfer model. The data in test folder is used for validating the efficacy of the domain transfer model.

The preprocessing step can be run as python3 data_classify.py /data/capstone/BigEarthNet-v1.0 output . The first parameter is the path to the input image dataset , the second folder is the output directory for generated folders.
